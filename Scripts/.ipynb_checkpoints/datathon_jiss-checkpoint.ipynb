{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conoco Phillips Dataset Challenge - Team J.J.I.S\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The initial portion of our code is import statements and our data cleaning function. We experimented with a variety of ways to process the data, mainly due to the issue of large amounts of 'na's being found within. One of the methods implemented was replacing all entries of 'na' with -1 , we also tried dropping all columns above a certain 'na' threshold. In the end we found that a threshold of 79% resulted in the highest score. This threshold was decided based on sensors 41, 42, and 43 being sequential while also having a similar amount of 'na' percentage, around 80%. \n",
    "\n",
    "We attempted a few methods of normalization within the data, such as standard and robust normalization. They were implemented using the standard scikit library functions StandardScaler and RobustScaler. However, we found that normalizing the data resulted in lower accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import settings\n",
    "import os\n",
    "os.chdir(\"../Data\")\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "# from sklearn import neighbors\n",
    "from sklearn.metrics import f1_score\n",
    "import seaborn as sns\n",
    "import collections\n",
    "\n",
    "\n",
    "def clean_data(df_clean):\n",
    "    # Drop columns with greater than 30% of values equal to na\n",
    "    columns = list(df_clean)\n",
    "    for col in columns:\n",
    "        try:\n",
    "            if df_clean[col].str.count('na').sum() > (60001 * .30):\n",
    "                df_clean = df_clean.drop(columns=[col])\n",
    "        except:\n",
    "            pass\n",
    "    # Count na's in row and drop rows with greater than 30%\n",
    "    df_clean['sum_na'] = df_clean.apply(lambda row: sum(row[0:60000]=='na'), axis=1)\n",
    "    df_done = df_clean[~(df_clean['sum_na'] >= (172 * .3))]\n",
    "    df_done = df_done.drop(columns=['sum_na'])\n",
    "    df_done = df_done.replace('na', -1)\n",
    "\n",
    "    return df_done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested machine learning algorithms such as SVM, Random Forest and AdaBoost. For the majority of experiments, random forest gave the best performance regardless of the cleaning or normalization method implemented. For random forest\n",
    "\n",
    "Another technique we attempted was non-negative matrix factorization. We converted all 'na's to -1, then shifted the entire dataset up by 1, resulting in 'na' being 0. We then converted it to an embedding space using scikit learns MF algorithm. The model was then stored as a pickled object and fed into our random forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    settings.init()\n",
    "\n",
    "    df_training = pd.read_csv(settings.training_data_cleaned)\n",
    "    df_drop = df_training.drop(columns=['id','target'])\n",
    "    df_drop = df_drop + 1\n",
    "\n",
    "    np_drop = df_drop.to_numpy()\n",
    "    model = NMF(n_components=2, init='random', random_state=0)\n",
    "    W = model.fit_transform(np_drop)\n",
    "\n",
    "    with open('new_matrix.pickle', 'wb') as handle:\n",
    "        pickle.dump(handle, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing...\n",
      "0.9932811738667893\n",
      "0.9944991630100894\n",
      "0.9938788002715931\n",
      "0.9923290043290043\n",
      "0.9940233126527541\n",
      "0.9916154233363534\n",
      "0.9934386723952305\n",
      "0.9950282648360711\n",
      "0.9930001940304126\n",
      "0.9952674292119769\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret input 'day'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5e0feec356b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mdicysort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'whitegrid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"day\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"total_bill\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdicysort\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36mbarplot\u001b[1;34m(x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge, ax, **kwargs)\u001b[0m\n\u001b[0;32m   3147\u001b[0m                           \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3148\u001b[0m                           \u001b[0morient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3149\u001b[1;33m                           errcolor, errwidth, capsize, dodge)\n\u001b[0m\u001b[0;32m   3150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3151\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[0;32m   1605\u001b[0m         \u001b[1;34m\"\"\"Initialize the plotter.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1606\u001b[0m         self.establish_variables(x, y, hue, data, orient,\n\u001b[1;32m-> 1607\u001b[1;33m                                  order, hue_order, units)\n\u001b[0m\u001b[0;32m   1608\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1609\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate_statistic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[1;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[0;32m    153\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m                     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Could not interpret input '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;31m# Figure out the plotting orientation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret input 'day'"
     ]
    }
   ],
   "source": [
    "def gen_output(predictions):\n",
    "    # columns = ['id', 'target']\n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    settings.init()\n",
    "    print(\"Executing...\")\n",
    "\n",
    "    df = pd.read_csv(settings.training_data)\n",
    "    X = df.iloc[:, 2:]  # First two columns are id and target\n",
    "    Y = np.array(df.iloc[:, 1])\n",
    "\n",
    "    # Algorithms\n",
    "    # knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "    alg = RandomForestClassifier(n_estimators=100)\n",
    "    # sv = svm.SVC(kernel='linear')\n",
    "    # ada = AdaBoostClassifier(n_estimators=100)\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "    fscores = []\n",
    "    for train, test in cv.split(X, Y):\n",
    "        model = alg.fit(X.iloc[train], Y[train])\n",
    "        Y_pred = model.predict(X.iloc[test])\n",
    "        fscore = f1_score(Y[test], Y_pred, average='weighted', labels=np.unique(Y[test]))\n",
    "        fscores.append(fscore)\n",
    "        print(fscore)\n",
    "        \n",
    "    importances = list(model.feature_importances_)\n",
    "    column_headers = list(df.columns.values)\n",
    "    dicy = dict(zip(importances,column_headers))\n",
    "    dicysort = collections.OrderedDict(sorted(dicy.items()))\n",
    "    sns.set(style='whitegrid')\n",
    "    ax = sns.barplot(x=\"day\", y=\"total_bill\", data=dict(dicysort))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Average F-measure:', sum(fscores) / len(fscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
